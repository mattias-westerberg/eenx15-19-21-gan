{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifiable Convolutional Neural Network\n",
    "\n",
    "This notebook can be used for testing and benchmarking different solutions for CNN's for different image datasets. The images can have variance in sizes and the parameters are easily controlled. Notice that by default, the images will be converted to grayscale.\n",
    "\n",
    "## Set up\n",
    "\n",
    "The structure of your dataset directory should look like this: (labels represents directories)\n",
    "\n",
    "<br>\n",
    "<p>parent directory</p>\n",
    "            <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|---> class 1</p>\n",
    "            <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|---> class 2</p>\n",
    "            <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|---> class ..</p>\n",
    "            <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|---> class n</p>\n",
    "\n",
    "Child directories must have the name of the classes you want to predict.\n",
    "<br>\n",
    "\n",
    "Variables to assign:\n",
    "- directory - String representation of path to the parent directory of the dataset.\n",
    "- labels - A list of all the different classes you want to predict (same name as the child directories in the data set folder).\n",
    "- image_width - The width, in pixels, all images will be scaled to.\n",
    "- image_height - The height, in pixels, all images will be scaled to.\n",
    "- perc_test - The percentage of the dataset that will be used for evaluationg your model.\n",
    "\n",
    "Your python interpreter should have the following modules installed:\n",
    "- NumPy\n",
    "- tensorflow or tensorflow-gpu\n",
    "- OpenCV\n",
    "\n",
    "\n",
    "## How to use\n",
    "\n",
    "Set up the parameters discussed above in the first code cell, then run it. This will create a uniform version of your dataset and it will be saved as a pickle file. If you want to make changes to your data set, these two cells must be executed again.\n",
    "\n",
    "In the second code cell, you assign a desirable name of the model. To prevent appending models to the same file, each filename will have a timestamp. Then you can set up various parameters for your training as well as setting up layers as you like in your neural network.\n",
    "This cell can then be run and the accuracy as well as loss will be printed out for each epoch and the final test. You can do further investigation of your model using TensorBoard (or other callbacks with slight refactoring of the script).\n",
    "\n",
    "The final code cell is used for testing your model on a specific image. This cell needs to be given a path to your image.\n",
    "\n",
    "### How open your model TensorBoard:\n",
    "1. Open a terminal with your python environment.\n",
    "2. cd to the folder this notebook is saved in.\n",
    "3. type tensorboard --logdir=logs/\n",
    "4. Open the link which the console window outputs in a browser.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import random\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "# Set up\n",
    "directory = r'C:/Users/Mattias/Documents/parent directory' # Path to dataset directory here (parent of the image folders)\n",
    "labels = ['Cat', 'Dog'] # List of the classes you want to predict\n",
    "image_width = 100 # The width all images will be scaled to\n",
    "image_height = 100 # The height all images will be scaled to\n",
    "perc_test = 20 # The percentage of the dataset that will be used for evaluationg your model\n",
    "\n",
    "\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for label in labels:\n",
    "        path = os.path.join(directory, label) # point correct label to correct folder\n",
    "        class_number = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                img_array = cv2.resize(img_array, (image_width, image_height))\n",
    "                training_data.append([img_array, class_number])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "create_training_data()\n",
    "random.shuffle(training_data)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for feature, label in training_data:\n",
    "    X.append(feature)\n",
    "    y.append(label)\n",
    "\n",
    "X = numpy.array(X).reshape(-1, image_width, image_height, 1)\n",
    "training_x = X[: int(len(X) - perc_test * len(X) / 100.0)]; test_x = X[int(len(X) - perc_test * len(X) / 100.0) :]\n",
    "training_y = y[: int(len(X) - perc_test * len(X) / 100.0)]; test_y = y[int(len(X) - perc_test * len(X) / 100.0) :]\n",
    "\n",
    "pickle_out = open(\"training_x.pickle\",\"wb\")\n",
    "pickle.dump(training_x, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"test_x.pickle\",\"wb\")\n",
    "pickle.dump(test_x, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"training_y.pickle\",\"wb\")\n",
    "pickle.dump(training_y, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"test_y.pickle\",\"wb\")\n",
    "pickle.dump(test_y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build, evaluate and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "# Set up\n",
    "model_name='test-{}'.format(time.time())\n",
    "validation_split = 0.2\n",
    "loss_function = 'sparse_categorical_crossentropy'\n",
    "optimizer = 'adam'\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "# gpu_options = tensorflow.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "# sess = tensorflow.Session(config=tensorflow.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu', input_shape=(image_width, image_height, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(len(labels), activation='softmax'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(model_name))\n",
    "\n",
    "model.compile(loss=loss_function,\n",
    "             optimizer=optimizer,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# Load the pickle files:\n",
    "pickle_in = open(\"training_x.pickle\", \"rb\")\n",
    "training_x = pickle.load(pickle_in)  # training images \n",
    "training_x = tensorflow.keras.utils.normalize(training_x, axis=1)\n",
    "#training_x = training_x / 255.0\n",
    "\n",
    "pickle_in = open(\"training_y.pickle\", \"rb\")\n",
    "training_y = pickle.load(pickle_in)  # training labels\n",
    "\n",
    "pickle_in = open(\"test_x.pickle\", \"rb\")\n",
    "test_x = pickle.load(pickle_in)  # test images \n",
    "test_x = tensorflow.keras.utils.normalize(test_x, axis=1)\n",
    "#test_x = test_x / 255.0\n",
    "\n",
    "pickle_in = open(\"test_y.pickle\", \"rb\")\n",
    "test_y = pickle.load(pickle_in)  # test labels\n",
    "\n",
    "model.fit(training_x, training_y, batch_size=batch_size, epochs=epochs, validation_split=validation_split, callbacks=[tensorboard])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_x, test_y)\n",
    "print('Loss: {}, Accuracy: {}'.format(test_loss, test_acc))\n",
    "\n",
    "model.save('{}.model'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "path = r'C:/Users/Mattias/Documents/image.jpg' # path to test image here\n",
    "\n",
    "def prepare(path):\n",
    "    img_array = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_array = cv2.resize(img_array, (image_width, image_height))\n",
    "    return img_array.reshape(-1, image_width, image_height, 1)\n",
    "\n",
    "\n",
    "model = tensorflow.keras.models.load_model(model_name + '.model')\n",
    "\n",
    "predictions = model.predict([prepare(path)])\n",
    "print(labels[numpy.argmax(predictions[0])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
